{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Load Diabetes dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 442 entries, 0 to 441\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   AGE          442 non-null    int64  \n",
      " 1   SEX          442 non-null    int64  \n",
      " 2   BMI          442 non-null    float64\n",
      " 3   BP           442 non-null    float64\n",
      " 4   S1           442 non-null    int64  \n",
      " 5   S2           442 non-null    float64\n",
      " 6   S3           442 non-null    float64\n",
      " 7   S4           442 non-null    float64\n",
      " 8   S5           442 non-null    float64\n",
      " 9   S6           442 non-null    int64  \n",
      " 10  PROGRESSION  442 non-null    int64  \n",
      "dtypes: float64(6), int64(5)\n",
      "memory usage: 38.1 KB\n",
      "Index(['AGE', 'SEX', 'BMI', 'BP', 'S1', 'S2', 'S3', 'S4', 'S5', 'S6',\n",
      "       'PROGRESSION'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('diabetes_dirty.csv')\n",
    "\n",
    "# Display first 5 rows\n",
    "df.head()\n",
    "\n",
    "# Get info about dataset\n",
    "df.info()\n",
    "df.describe()\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Separate independent variables (x) and dependent variable (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the target column is named 'progression'\n",
    "x = df.drop('PROGRESSION', axis=1)\n",
    "y = df['PROGRESSION']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: Split the dataset into training (80%) and testing (20%) sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6: Investigate the need for scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basic statistics of features before scaling:\n",
      "              AGE         SEX         BMI          BP          S1          S2  \\\n",
      "count  353.000000  353.000000  353.000000  353.000000  353.000000  353.000000   \n",
      "mean    47.974504    1.473088   26.319263   94.216176  189.246459  115.933428   \n",
      "std     13.163393    0.499984    4.500748   13.734541   34.705644   31.070428   \n",
      "min     19.000000    1.000000   18.000000   62.000000   97.000000   43.400000   \n",
      "25%     37.000000    1.000000   23.100000   84.000000  165.000000   95.000000   \n",
      "50%     49.000000    1.000000   25.700000   93.000000  186.000000  113.400000   \n",
      "75%     58.000000    2.000000   29.400000  104.000000  209.000000  134.600000   \n",
      "max     79.000000    2.000000   42.200000  131.000000  301.000000  242.400000   \n",
      "\n",
      "               S3          S4          S5          S6  \n",
      "count  353.000000  353.000000  353.000000  353.000000  \n",
      "mean    49.907932    4.061416    4.626146   90.600567  \n",
      "std     13.136116    1.279639    0.515481   11.129746  \n",
      "min     23.000000    2.000000    3.258100   60.000000  \n",
      "25%     41.000000    3.000000    4.262700   82.000000  \n",
      "50%     48.000000    4.000000    4.615100   91.000000  \n",
      "75%     58.000000    5.000000    4.990400   98.000000  \n",
      "max     99.000000    9.090000    6.107000  124.000000  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\nBasic statistics of features before scaling:\")\n",
    "print(x_train.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling is beneficial for Linear models to ensure equal weightings and better convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 7: Apply MinMaxScaler and StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "minmax_scaler = MinMaxScaler()\n",
    "standard_scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit on training set\n",
    "x_train_minmax = minmax_scaler.fit_transform(x_train)\n",
    "x_test_minmax = minmax_scaler.transform(x_test)\n",
    "\n",
    "x_train_standard = standard_scaler.fit_transform(x_train)\n",
    "x_test_standard = standard_scaler.transform(x_test)\n",
    "\n",
    "# I'll proceed with StandardScaler as it centers the data (mean = 0), which is useful for regression\n",
    "x_train_scaled = x_train_standard\n",
    "x_test_scaled = x_test_standard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 8: Train a multiple linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(x_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 9: Print model for intercept and co-efficient "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Intercept: 149.371104815864\n",
      "Model Co-efficient: [  0.43173753 -10.83023146  21.55710633  18.3618367  -46.39086961\n",
      "  29.55538306   6.83028374   7.4709764   37.76758745   2.32775   ]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nModel Intercept:\", model.intercept_)\n",
    "print('Model Co-efficient:', model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 10: Generate predictions using the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 11: Evalaute model performance with R-squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "R-squared score on test data: 0.483548993101371\n",
      "Weak fit. Consider improving data quality, feature selection, or trying a different model.\n"
     ]
    }
   ],
   "source": [
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"\\nR-squared score on test data:\", r2)\n",
    "\n",
    "# Interpretation note\n",
    "if r2 >= 0.75:\n",
    "    print(\"Good model fit.\")\n",
    "elif r2 >= 0.5:\n",
    "    print(\"Moderate fit. Consider checking for multicollinearity or feature engineering.\")\n",
    "else:\n",
    "    print(\"Weak fit. Consider improving data quality, feature selection, or trying a different model.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
